# v1.6 Epic - Execution Efficiency and Learning Loop Quality

Date: 2026-02-17  
Release: `v1.6`  
Status: Completed (merged to `develop`)

## Problem

The current system is safe but not consistently efficient:

1. Read-heavy tool stages often execute serially even when independent.
2. Repeated tool inventory/planning overhead adds avoidable latency.
3. Learning outputs are captured, but policy adaptation quality is still coarse.

## Epic Goal

Improve throughput and decision quality by combining orchestration efficiency with stronger learning-loop feedback signals.

## Product Contract

1. Analysis requests remain analysis-only unless explicit execution intent is detected.
2. Mutating tools remain serialized and safety-gated.
3. Read-only tools may run concurrently with bounded parallelism.
4. Closed-trade learning artifacts are deterministic, auditable, and policy-consumable.

## Workstreams

## 1) Orchestrator Concurrency

1. Introduce ready-step batching for independent read-only steps.
2. Execute read-only steps in parallel (default max concurrency: 3).
3. Preserve deterministic completion records and planner state transitions.

Acceptance criteria:
1. Planner executes independent read steps concurrently.
2. Mutating steps continue to run one-at-a-time.

Test requirements:
1. Unit tests for ready-step selection and batch execution.
2. Regression tests for autonomous trade flow ordering.

## 2) Redundant-Call Elimination

1. Skip duplicate `tools.list`/inventory calls when previous cycle state is still valid.
2. Emit synthetic completion artifact for skipped steps so plan progression remains deterministic.
3. Track skip counts in traces for observability.

Acceptance criteria:
1. Duplicate inventory calls are removed from same-cycle plans.
2. No planner deadlocks from skipped-step handling.

Test requirements:
1. Tests asserting skip behavior and successful plan completion.

## 3) Intent Guardrails for Mutating Tools

1. Add analysis-style intent classification for chat goals.
2. Block mutating perps tools during analysis-style requests unless explicit execution intent exists.
3. Return clear rationale in execution trace when a mutating step is blocked.

Acceptance criteria:
1. `perp_place_order` and `perp_cancel_order` are blocked in analysis contexts.
2. Explicit trade intents still execute normally.

Test requirements:
1. Intent-gating tests for positive and negative cases.

## 4) Learning Loop Attribution Upgrade

1. Extend closed-trade artifacts with counterfactuals:
- hold-to-X delta,
- half-size delta,
- early/late exit deltas.
2. Tag each trade with dominant error type:
- direction,
- timing,
- sizing,
- exit,
- execution friction.
3. Add rolling-window aggregates used directly by autonomy policy.

Acceptance criteria:
1. All closed trades include attribution and counterfactual diagnostics.
2. Rolling error mix is queryable for policy control.

Test requirements:
1. Deterministic fixture tests for counterfactual calculations.
2. Policy tests verifying parameter downshift/upshift from error mix.

## 5) Policy Adaptation from Learning Signals

1. Map error distributions to bounded policy adjustments:
- minEdge,
- size multiplier,
- max trades per scan,
- observation sensitivity.
2. Add hysteresis so policy does not oscillate on small sample noise.
3. Persist adaptation decisions with rationale.

Acceptance criteria:
1. Policy reacts to meaningful degradation and recovers gradually.
2. Adjustments are auditable and bounded.

Test requirements:
1. Simulation tests for degrade/recover scenarios.

## 6) Operator Observability

1. Add latency KPIs and skip/parallel metrics to status/debug surfaces.
2. Include learning-loop quality snapshot (recent error mix + adaptation state).
3. Ensure output remains concise for Telegram delivery.

Acceptance criteria:
1. Operator can inspect both efficiency and learning quality in one status response.

Test requirements:
1. Snapshot formatting and field-presence tests.

## Sprint Task/Branch Plan

1. `feat/v1.6-orchestrator-read-concurrency`
2. `feat/v1.6-redundant-tool-inventory-elision`
3. `feat/v1.6-intent-safe-mutation-gates`
4. `feat/v1.6-trade-counterfactual-attribution`
5. `feat/v1.6-policy-adaptation-from-error-mix`
6. `feat/v1.6-status-efficiency-quality-telemetry`
7. `feat/v1.6-integration-latency-quality-acceptance`

## Definition of Done

1. All branch acceptance criteria met and merged into `develop`. ✅
2. Full test suite + typecheck green on `develop`. ✅
3. End-to-end staging run confirms:
- lower cycle latency,
- no analysis-triggered accidental execution,
- improved policy adaptation observability.

## Closure Notes

Merged and validated on `develop`:

1. `feat(v1.6): enforce deterministic mechanical expression selection` (`aeca3d0`)
2. `feat(v1.6): add immutable scan cycle snapshot metadata` (`ac6b243`)
3. `feat(v1.6): add market metadata and mids cache for hyperliquid markets` (`4e813c7`)
4. `feat(v1.6): add cooldown-based event-driven scan triggers` (`46d046d`)
5. `feat(v1.6): add deterministic perp order input contract validation` (`9d8543d`)
6. `feat(v1.6): classify terminal vs retryable tool failures` (`55306f4`)
7. `feat(v1.6): enforce IOC quote freshness before submit` (`36d56fd`)
8. `feat(v1.6): add non-blocking async llm execution enrichment` (`b6c93ff`)
9. `feat(v1.6): add autonomous scan performance telemetry` (`98fd5f6`)
10. `feat(v1.6): add performance acceptance budget evaluator` (`b7b6c25`)

Stabilization follow-up (v1.6.1):
1. LLM burst controls and active-chat suppression merged (`8e232a1`).
2. Build/test health restoration merged (`6c0a949`).
3. Post-stabilization baseline advanced to `d71dee0` on `develop`.

Active follow-up branch:
1. `feat/v1.6.1-scheduled-report-jobs` (generic scheduled-task surface + scheduling-intent guardrail).
